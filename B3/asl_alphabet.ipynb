{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d9ba8a7",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77e323b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\ADMIN\\.cache\\kagglehub\\datasets\\grassknoted\\asl-alphabet\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "path = kagglehub.dataset_download(\"grassknoted/asl-alphabet\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "DATA_DIR = os.path.join(\n",
    "    path,\n",
    "    \"asl_alphabet_train\",\n",
    "    \"asl_alphabet_train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9dc016",
   "metadata": {},
   "source": [
    "# Import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e209b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef1a408",
   "metadata": {},
   "source": [
    "# Chuan hoa du lieu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "486b9f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9288f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cai thien datagen\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6915ae26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 69623 images belonging to 2 classes.\n",
      "Found 17405 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = datagen.flow_from_directory(\n",
    "    path,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\" # chi dinh lay tap train\n",
    ")\n",
    "\n",
    "val_data = datagen.flow_from_directory(\n",
    "    path,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\" # chi dinh lay tap validation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60e8f44",
   "metadata": {},
   "source": [
    "# Khai bao mo hinh - fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccb2a098",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),  # increase dropout\n",
    "    Dense(29)  # no activation here, use from_logits=True\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2f9245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", input_shape=(64,64,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(train_data.num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea4d42bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret optimizer identifier: admin",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# huan luyen\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43madmin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCategoricalCrossentropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrom_logits\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maccuracy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m history = model.fit(\n\u001b[32m      8\u001b[39m     train_data,\n\u001b[32m      9\u001b[39m     epochs=\u001b[32m10\u001b[39m,\n\u001b[32m     10\u001b[39m     validation_data=val_data\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m model.summary()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:98\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(identifier)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, Optimizer):\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not interpret optimizer identifier: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Could not interpret optimizer identifier: admin"
     ]
    }
   ],
   "source": [
    "# huan luyen\n",
    "model.compile(\n",
    "    optimizer=\"admin\",\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=10,\n",
    "    validation_data=val_data\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f360170e",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47659a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model\n"
     ]
    }
   ],
   "source": [
    "model.save(\"asl_alphabet_model.h5\") # .h5 dung de load lai va du doan cho sau nay\n",
    "print(\"Saved model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3167245e",
   "metadata": {},
   "source": [
    "# Danh gia mo hinh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7506a022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m544/544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.9997 - loss: 0.0026\n",
      "Accuracy: 0.9997\n",
      "Loss: 0.0026\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(val_data)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42722715",
   "metadata": {},
   "source": [
    "# Du doan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58716e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load mo hinh\n",
    "loaded_model = keras.models.load_model(\"asl_alphabet_model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7b8fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asl_alphabet_test', 'asl_alphabet_train']\n"
     ]
    }
   ],
   "source": [
    "# chuan bi label {chu cai}\n",
    "class_names = list(train_data.class_indices.keys())\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e6c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 1 hinh de xu ly\n",
    "img_dir = os.path.join(path, \"asl_alphabet_train\", \"asl_alphabet_train\", \"M\")  # duong dan den thu muc chua hinh\n",
    "# Get first image file\n",
    "img_file = os.listdir(img_dir)[0]\n",
    "img_path = os.path.join(img_dir, img_file) # duong dan den hinh can du doan\n",
    "# img_path = input(\"Enter the path of the image to predict: \")\n",
    "img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = img_array / 255.0  # scale anh\n",
    "img_array = np.expand_dims(img_array, axis=0)  # them kich thuoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f20f7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "[[0.00708671 0.9929133 ]]\n",
      "Predicted label: asl_alphabet_train\n"
     ]
    }
   ],
   "source": [
    "# du doan\n",
    "prediction = loaded_model.predict(img_array)\n",
    "predicted_index = np.argmax(prediction)\n",
    "predicted_label = class_names[predicted_index]\n",
    "\n",
    "# print % cac lop du doan\n",
    "print(prediction)\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

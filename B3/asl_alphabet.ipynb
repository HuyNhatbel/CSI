{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d9ba8a7",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77e323b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading to C:\\Users\\ADMIN\\.cache\\kagglehub\\datasets\\grassknoted\\asl-alphabet\\1.archive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.03G/1.03G [01:42<00:00, 10.8MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\ADMIN\\.cache\\kagglehub\\datasets\\grassknoted\\asl-alphabet\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"grassknoted/asl-alphabet\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9dc016",
   "metadata": {},
   "source": [
    "# Import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e209b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef1a408",
   "metadata": {},
   "source": [
    "# Chuan hoa du lieu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "486b9f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9288f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255, # chuyen doi gtri [0,255] ve [0,1]\n",
    "    validation_split=0.2 # Chia du lieu thanh 80% train va 20% validation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6915ae26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 69623 images belonging to 2 classes.\n",
      "Found 17405 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = datagen.flow_from_directory(\n",
    "    path,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\" # chi dinh lay tap train\n",
    ")\n",
    "\n",
    "val_data = datagen.flow_from_directory(\n",
    "    path,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\" # chi dinh lay tap validation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60e8f44",
   "metadata": {},
   "source": [
    "# Khai bao mo hinh - fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ccb2a098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Conv2D name=conv2d_18, built=False>,\n",
       " <MaxPooling2D name=max_pooling2d_18, built=True>,\n",
       " <Conv2D name=conv2d_19, built=False>,\n",
       " <MaxPooling2D name=max_pooling2d_19, built=True>,\n",
       " <Conv2D name=conv2d_20, built=False>,\n",
       " <MaxPooling2D name=max_pooling2d_20, built=True>,\n",
       " <Flatten name=flatten_6, built=False>,\n",
       " <Dense name=dense_12, built=False>,\n",
       " <Dropout name=dropout_6, built=True>,\n",
       " <Dense name=dense_13, built=False>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential\n",
    "(\n",
    "    [\n",
    "        keras.layers.Conv2D(32,(3,3), activation=\"relu\", input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "        keras.layers.MaxPooling2D((2,2)),\n",
    "        \n",
    "        keras.layers.Conv2D(64,(3,3), activation=\"relu\"),\n",
    "        keras.layers.MaxPooling2D((2,2)),\n",
    "        \n",
    "        keras.layers.Conv2D(128,(3,3), activation=\"relu\"),\n",
    "        keras.layers.MaxPooling2D((2,2)),\n",
    "        \n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(512, activation=\"relu\"), # fully connected layer\n",
    "        keras.layers.Dropout(0.5), # dropout de tranh overfitting\n",
    "        keras.layers.Dense(29,activation=\"softmax\") # 29 classes trong asl\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2f9245e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", input_shape=(64,64,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(train_data.num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4d42bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2005/2176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2:58\u001b[0m 1s/step - accuracy: 0.9984 - loss: 0.0159"
     ]
    }
   ],
   "source": [
    "# huan luyen\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=10,\n",
    "    validation_data=val_data\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f360170e",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47659a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"asl_alphabet_model.h5\") # .h5 dung de load lai va du doan cho sau nay\n",
    "print(\"Saved model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3167245e",
   "metadata": {},
   "source": [
    "# Danh gia mo hinh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7506a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(val_data)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42722715",
   "metadata": {},
   "source": [
    "# Du doan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58716e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mo hinh\n",
    "loaded_model = keras.model.load_model(\"asl_alphabet_model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7b8fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chuan bi label {chu cai}\n",
    "class_names = list(train_data.class_indices.keys())\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e6c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 1 hinh de xu ly\n",
    "img_path = path + \"/test.jpg\" # duong dan den hinh can du doan\n",
    "img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "img_array = image.image_to_array(img)\n",
    "img_array = img_array / 255.0 # scale anh\n",
    "img_array = np.expand_dims(img_array, axis=0) # them kick thuoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f20f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# du doan\n",
    "prediction = loaded_model.predict(img_array)\n",
    "predicted_index = np.argmax(prediction)\n",
    "predicted_label = class_names[predicted_index]\n",
    "\n",
    "# print % cac lop du doan\n",
    "print(prediction)\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
